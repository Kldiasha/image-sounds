{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Goal = build autoencoder for audio file\n",
    "    1. Get nn to train\n",
    "    2. Show that low error (and visually inspect) for the STFTs\n",
    "    3. Do iSTFT and audially compare \n",
    "\n",
    "Lower input dimension of audio\n",
    "Use low # of channels, and pooling/stride in the network \n",
    "\n",
    "Build out simple network, train on collab, slowly make more complex\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy import signal\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "TEST_LOSS_EPOCH_FREQ = 4\n",
    "NUM_SPECTROGRAM_VISUALIZATION_PLOTS = 3\n",
    "RUN = 2\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "BOTTLENECK_SIZE = 1000\n",
    "\n",
    "MODELNAME = \"SecondTry\"\n",
    "ROOT_FILENAME = 'Dataloader'\n",
    "SEED = 1 \n",
    "BATCH_SIZE = 20\n",
    "DATA_PER_FILE = 50\n",
    "DATA_FILE = pickle_file = '/content/drive/MyDrive/Dataloaders/' + ROOT_FILENAME + '_BS' + str(BATCH_SIZE) + '_DPF' + str(DATA_PER_FILE) + '_S' + str(SEED) + '.pkl'\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X[index]\n",
    "        y = self.Y[index]\n",
    "        return x, y\n",
    "    \n",
    "with open(DATA_FILE, 'rb') as file:\n",
    "    train_loader, test_loader = pickle.load(file)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    # input_shape probably 260 x 90, it is a 2d tuple\n",
    "    # bottleneck size is just a number that is the size of 1d nodes between encoder and decoder\n",
    "    def __init__(self, input_shape, bottleneck_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        flattened_size = input_shape[0]*input_shape[1]*input_shape[2]\n",
    "        max_channels = 32\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, stride=(1, 1), kernel_size=(3, 3), padding='same'),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            # nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Conv2d(16, max_channels, stride=(1, 1), kernel_size=(3, 3), padding='same'),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            # nn.MaxPool2d(kernel_size=(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(max_channels * flattened_size, 1000)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(1000, max_channels * flattened_size),\n",
    "            nn.Unflatten(1, (max_channels, 260, 90)),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            # nn.MaxUnpool2d(),\n",
    "            nn.ConvTranspose2d(32, 16, stride=(1, 1), kernel_size=(3, 3), padding=1),\n",
    "            # nn.MaxUnpool2d(),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(16, 1, stride=(1, 1), kernel_size=(3, 3), padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the Autoencoder\n",
    "autoencoder = AutoEncoder((260, 90, 1), BOTTLENECK_SIZE)\n",
    "\n",
    "# Define the loss function\n",
    "reconstruction_loss_fn = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = NUM_EPOCHS\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device is ', device)\n",
    "autoencoder.to(device)\n",
    "\n",
    "\n",
    "print(\"hello\")\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    for X_batch, _ in tqdm(train_loader):\n",
    "        y_batch = X_batch # we are doing an autoencoder so want to get the same thing\n",
    "        print(X_batch.shape)\n",
    "        X_batch = X_batch.view(BATCH_SIZE, -1, 260, 90).to(device)\n",
    "        print(X_batch.shape)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        X_pred = autoencoder(X_batch)\n",
    "\n",
    "        # Compute the loss\n",
    "        constr_loss = reconstruction_loss_fn(X_pred, X_batch)\n",
    "        loss = constr_loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {average_loss}\")\n",
    "\n",
    "    # Calculate and print test loss every TEST_LOSS_EPOCH_FREQ epochs\n",
    "    if (epoch+1) % TEST_LOSS_EPOCH_FREQ == 0:\n",
    "        autoencoder.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.0\n",
    "            for X_test_batch, _ in test_loader:\n",
    "                X_test_batch = X_test_batch.view(BATCH_SIZE, -1, 260, 90).to(device)\n",
    "                X_pred_test = autoencoder(X_test_batch)\n",
    "                test_loss += reconstruction_loss_fn(X_pred_test, X_test_batch).item()\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Test Loss: {test_loss / len(test_loader)}\")\n",
    "        autoencoder.train()\n",
    "\n",
    "    end = time.time()\n",
    "    dur = end - start\n",
    "    if dur > 3600:\n",
    "        print(f\"Elapsed {epoch} number of epochs.\")\n",
    "        num_epochs = epoch\n",
    "        break\n",
    "\n",
    "    weight_file_name = f'model_{epoch}_{len(train_loader)}'\n",
    "    torch.save(autoencoder.state_dict(), weight_file_name)\n",
    "\n",
    "\n",
    "# Calculate final test loss\n",
    "autoencoder.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    for X_test_batch, _ in test_loader:\n",
    "        X_test_batch = X_test_batch.view(BATCH_SIZE, -1, 260, 90).to(device)\n",
    "        X_pred_test = autoencoder(X_test_batch)\n",
    "        test_loss += reconstruction_loss_fn(X_pred_test, X_test_batch).item()\n",
    "    print(f\"Final Test Loss: {test_loss / len(test_loader)}\")\n",
    "autoencoder.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np \n",
    "\n",
    "if not os.path.exists('autoencoder'):\n",
    "    os.makedirs('autoencoder')\n",
    "NUM_SPECTROGRAM_VISUALIZATION_PLOTS = 10\n",
    "autoencoder.eval()\n",
    "i = -1\n",
    "with torch.no_grad():\n",
    "    for batch_number, (X_test_batch, _) in enumerate(test_loader):\n",
    "        for k in range(X_test_batch.shape[0]):\n",
    "          i += 1\n",
    "          if i >= NUM_SPECTROGRAM_VISUALIZATION_PLOTS:\n",
    "              break\n",
    "          X_test_batch = X_test_batch.view(BATCH_SIZE, -1, 260, 90).to(device)\n",
    "          X_pred_test = autoencoder(X_test_batch)\n",
    "          print('The values for i = ', i, '  ', X_pred_test)\n",
    "\n",
    "          # Select the ith example from the batch\n",
    "          original = X_test_batch[0].cpu().numpy()\n",
    "          reconstructed = X_pred_test[0].cpu().numpy()\n",
    "\n",
    "          # Squeeze the arrays to remove single-dimensional entries\n",
    "          original = np.squeeze(original)\n",
    "          reconstructed = np.squeeze(reconstructed)\n",
    "\n",
    "          fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "          axs[0].imshow(original, aspect='auto', cmap='jet')\n",
    "          axs[0].set_title('Original')\n",
    "\n",
    "          axs[1].imshow(reconstructed, aspect='auto', cmap='jet')\n",
    "          axs[1].set_title('Reconstructed')\n",
    "\n",
    "\n",
    "          datafile = 'autoencoder/' 'SET_' + MODELNAME + '_BS' + str(BATCH_SIZE) + '_DPF' + str(DATA_PER_FILE) + '_S' + str(SEED) + f'example_{i}' + '.png'\n",
    "          plt.savefig(datafile)\n",
    "          plt.close(fig)\n",
    "\n",
    "autoencoder.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
